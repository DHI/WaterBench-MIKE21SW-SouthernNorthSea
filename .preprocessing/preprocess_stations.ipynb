{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6329c38",
   "metadata": {},
   "source": [
    "# Preprocess stations\n",
    "In this noteook we load the nc files for the stations in stations.txt and convert to csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5252410d",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206778aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4985232",
   "metadata": {},
   "source": [
    "### Open and read stations in txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25bae21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6200144', '6200145', '6201045', '6201047', '6201050']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"stations.txt\", \"r\") as f:\n",
    "    station_files = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Print a subset of the station files\n",
    "station_files[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429638ee",
   "metadata": {},
   "source": [
    "### Open and read file names in txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b746b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INSITU_GLO_PHYBGCWAV_DISCRETE_MYNRT_013_030/cmems_obs-ins_glo_phybgcwav_mynrt_na_irr_202311/monthly/MO/202201/NO_TS_MO_6200144_202201.nc',\n",
       " 'INSITU_GLO_PHYBGCWAV_DISCRETE_MYNRT_013_030/cmems_obs-ins_glo_phybgcwav_mynrt_na_irr_202311/monthly/MO/202202/NO_TS_MO_6200144_202202.nc',\n",
       " 'INSITU_GLO_PHYBGCWAV_DISCRETE_MYNRT_013_030/cmems_obs-ins_glo_phybgcwav_mynrt_na_irr_202311/monthly/MO/202203/NO_TS_MO_6200144_202203.nc']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get full file names from output.txt\n",
    "with open(\"output.txt\", \"r\") as f:\n",
    "    file_names = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Print a subset of the file names\n",
    "file_names[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bd7c8e",
   "metadata": {},
   "source": [
    "### Convert nc files to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff143a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped saving 6200144.csv (file already exists)\n",
      "Skipped saving 6200145.csv (file already exists)\n",
      "Skipped saving 6201045.csv (file already exists)\n",
      "Skipped saving 6201047.csv (file already exists)\n",
      "Skipped saving 6201050.csv (file already exists)\n",
      "Skipped saving 6201059.csv (file already exists)\n",
      "Skipped saving A121_.csv (file already exists)\n",
      "Skipped saving AkkaertSouthwestBuoy.csv (file already exists)\n",
      "Skipped saving Europlatform2.csv (file already exists)\n",
      "Skipped saving Europlatform3.csv (file already exists)\n",
      "Skipped saving F3platform.csv (file already exists)\n",
      "Skipped saving IJmuidenMunitiestort_.csv (file already exists)\n",
      "Skipped saving J61.csv (file already exists)\n",
      "Skipped saving K13a_.csv (file already exists)\n",
      "Skipped saving K141_.csv (file already exists)\n",
      "Skipped saving KeetenBoei.csv (file already exists)\n",
      "Skipped saving KwintebankBuoy.csv (file already exists)\n",
      "Skipped saving L91_.csv (file already exists)\n",
      "Skipped saving LichteilandGoeree1_.csv (file already exists)\n",
      "Skipped saving MaeslantkeringZeezijdeNoordMeetpaal.csv (file already exists)\n",
      "Skipped saving MaeslantkeringZeezijdeZuidMeetpaal.csv (file already exists)\n",
      "Skipped saving NieuwpoortBuoy.csv (file already exists)\n",
      "Skipped saving Nymindegab.csv (file already exists)\n",
      "Skipped saving Oosterschelde11.csv (file already exists)\n",
      "Skipped saving OstendEasternPalisadeBuoy.csv (file already exists)\n",
      "Skipped saving OverloopVanValkenisse.csv (file already exists)\n",
      "Skipped saving PasVanTerneuzenBoei.csv (file already exists)\n",
      "Skipped saving Q1_.csv (file already exists)\n",
      "Skipped saving WaddenEierlandseGat.csv (file already exists)\n",
      "Skipped saving WesthinderBuoy.csv (file already exists)\n",
      "Skipped saving ZeebruggeZandopvangkadeBuoy.csv (file already exists)\n",
      "Skipped saving ZwinBuoy.csv (file already exists)\n"
     ]
    }
   ],
   "source": [
    "# Define observation folder\n",
    "obs_fldr = 'raw-data'\n",
    "\n",
    "for station in station_files:\n",
    "    stations_data = []\n",
    "\n",
    "    for name in file_names:\n",
    "        if station in name:\n",
    "            # Load the NetCDF file if the path exists\n",
    "            basename = os.path.basename(name)\n",
    "            file_path = os.path.join(obs_fldr, basename)\n",
    "\n",
    "            if os.path.exists(file_path):\n",
    "                ds = xr.open_dataset(file_path)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # Convert to dataframe\n",
    "            df = ds.to_dataframe().reset_index()\n",
    "\n",
    "            # Extract the wanted variables\n",
    "            cols = ['TIME']\n",
    "\n",
    "            if 'VHM0' in df.columns:\n",
    "                cols.append('VHM0')\n",
    "\n",
    "            if 'VTZA' in df.columns:\n",
    "                cols.append('VTZA')\n",
    "\n",
    "            if 'VMDR' in df.columns:\n",
    "                cols.append('VMDR')\n",
    "            \n",
    "            if 'VTPK' in df.columns:\n",
    "                cols.append('VTPK')\n",
    "                \n",
    "            df = df[cols].copy()\n",
    "            df = df.dropna()\n",
    "\n",
    "            stations_data.append(df)\n",
    "    \n",
    "    # Convert to csv\n",
    "    full_df = pd.concat(stations_data)\n",
    "    csv_path = f\"../observations/{station}.csv\"\n",
    "\n",
    "    if not os.path.exists(csv_path):\n",
    "        full_df.to_csv(csv_path, index=False)\n",
    "        print(f\"Saved {station}.csv\")\n",
    "    else:\n",
    "        print(f\"Skipped saving {station}.csv (file already exists)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WaterBench-MIKE21SW-SouthernNorthSea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
