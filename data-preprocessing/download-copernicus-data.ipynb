{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a87e88b",
   "metadata": {},
   "source": [
    "# Copernicus data\n",
    "In this notebook we download observation data from Copernicus for some chosen stations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba57da6e",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4cbb61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copernicusmarine\n",
    "from pprint import pprint\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9500ae0",
   "metadata": {},
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bd500cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'mjessen'\n",
    "password = 'gM-Rzb4cS4Lwudk'\n",
    "dataset_id = 'cmems_obs-ins_glo_phybgcwav_mynrt_na_irr'\n",
    "part = 'latest'\n",
    "params_cat = 'waves'\n",
    "feature = 'TS'\n",
    "\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-12-31'\n",
    "\n",
    "north = 56\n",
    "south = 50\n",
    "west = -2\n",
    "east = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a02db89",
   "metadata": {},
   "source": [
    "### Read index file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7d89e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(542559, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['# product_id', 'file_name', 'geospatial_lat_min', 'geospatial_lat_max',\n",
       "       'geospatial_lon_min', 'geospatial_lon_max', 'time_coverage_start',\n",
       "       'time_coverage_end', 'institution', 'date_update', 'data_mode',\n",
       "       'parameters'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"copernicus-data/index_monthly.txt\", skiprows=5)\n",
    "print(df.shape)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71d6040",
   "metadata": {},
   "source": [
    "### Filter stations by location and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cd8ca65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 12)\n",
      "NO_TS_MO_6200041_202201.nc\n",
      "NO_TS_MO_6200042_202201.nc\n",
      "NO_TS_MO_6200170_202201.nc\n",
      "NO_TS_MO_6200304_202201.nc\n",
      "NO_TS_MO_6200305_202201.nc\n",
      "NO_TS_MO_6201008_202201.nc\n",
      "NO_TS_MO_6201009_202201.nc\n",
      "NO_TS_MO_6201010_202201.nc\n",
      "NO_TS_MO_6201011_202201.nc\n",
      "NO_TS_MO_6201012_202201.nc\n",
      "NO_TS_MO_6201013_202201.nc\n",
      "NO_TS_MO_6201014_202201.nc\n",
      "NO_TS_MO_6201015_202201.nc\n",
      "NO_TS_MO_6201017_202201.nc\n",
      "NO_TS_MO_6201018_202201.nc\n",
      "NO_TS_MO_6201019_202201.nc\n",
      "NO_TS_MO_6201045_202201.nc\n",
      "NO_TS_MO_6201047_202201.nc\n",
      "NO_TS_MO_6201050_202201.nc\n",
      "NO_TS_MO_6201051_202201.nc\n",
      "NO_TS_MO_6201052_202201.nc\n",
      "NO_TS_MO_6201059_202201.nc\n",
      "NO_TS_MO_6201067_202201.nc\n",
      "NO_TS_MO_6201068_202201.nc\n",
      "NO_TS_MO_6201082_202201.nc\n",
      "NO_TS_MO_6201083_202201.nc\n",
      "NO_TS_MO_6202108_202201.nc\n",
      "NO_TS_MO_6202110_202201.nc\n",
      "NO_TS_MO_6202112_202201.nc\n",
      "NO_TS_MO_6202600_202201.nc\n",
      "NO_TS_MO_6202601_202201.nc\n",
      "NO_TS_MO_6202602_202201.nc\n",
      "NO_TS_MO_6202603_202201.nc\n",
      "NO_TS_MO_A121_202201.nc\n",
      "NO_TS_MO_A122_202201.nc\n",
      "NO_TS_MO_A2Buoy_202201.nc\n",
      "NO_TS_MO_AWG_202201.nc\n",
      "NO_TS_MO_AkkaertSouthwestBuoy_202201.nc\n",
      "NO_TS_MO_Bath_202201.nc\n",
      "NO_TS_MO_BolVanHeistBuoy_202201.nc\n",
      "NO_TS_MO_Brouwershavensegat_202201.nc\n",
      "NO_TS_MO_CadzandBoei_202201.nc\n",
      "NO_TS_MO_Deurlo_202201.nc\n",
      "NO_TS_MO_DomburgerRassen_202201.nc\n",
      "NO_TS_MO_EurogeulDWE_202201.nc\n",
      "NO_TS_MO_EurogeulE13_202201.nc\n",
      "NO_TS_MO_Europlatform2_202201.nc\n",
      "NO_TS_MO_Europlatform3_202201.nc\n",
      "NO_TS_MO_F3platform_202201.nc\n",
      "NO_TS_MO_Fanoebugt_202201.nc\n",
      "NO_TS_MO_Hansweert_202201.nc\n",
      "NO_TS_MO_HonteSloehaven_202201.nc\n",
      "NO_TS_MO_IJmuidenMunitiestort2_202201.nc\n",
      "NO_TS_MO_IJmuidenMunitiestort_202201.nc\n",
      "NO_TS_MO_J61_202201.nc\n",
      "NO_TS_MO_K13a2_202201.nc\n",
      "NO_TS_MO_K13a3_202201.nc\n",
      "NO_TS_MO_K13a_202201.nc\n",
      "NO_TS_MO_K141_202201.nc\n",
      "NO_TS_MO_KeetenBoei_202201.nc\n",
      "NO_TS_MO_KwintebankBuoy_202201.nc\n",
      "NO_TS_MO_L91_202201.nc\n",
      "NO_TS_MO_LichteilandGoeree1_202201.nc\n",
      "NO_TS_MO_LichteilandGoeree2_202201.nc\n",
      "NO_TS_MO_MaeslantkeringZeezijdeNoordMeetpaal_202201.nc\n",
      "NO_TS_MO_MaeslantkeringZeezijdeZuidMeetpaal_202201.nc\n",
      "NO_TS_MO_MeetboeiRZGN1_202201.nc\n",
      "NO_TS_MO_MeetboeiWEO1_202201.nc\n",
      "NO_TS_MO_MeetboeiWEW1_202201.nc\n",
      "NO_TS_MO_NieuwpoortBuoy_202201.nc\n",
      "NO_TS_MO_Nymindegab_202201.nc\n",
      "NO_TS_MO_Oosterschelde11_202201.nc\n",
      "NO_TS_MO_Oosterschelde4_202201.nc\n",
      "NO_TS_MO_OstendEasternPalisadeBuoy_202201.nc\n",
      "NO_TS_MO_OstendNorthBuoy_202201.nc\n",
      "NO_TS_MO_OstendPoortjesBuoy_202201.nc\n",
      "NO_TS_MO_OverloopVanValkenisse_202201.nc\n",
      "NO_TS_MO_PasVanTerneuzenBoei_202201.nc\n",
      "NO_TS_MO_Q11_202201.nc\n",
      "NO_TS_MO_Q1_202201.nc\n",
      "NO_TS_MO_Raversijde1Buoy_202201.nc\n",
      "NO_TS_MO_Raversijde2Buoy_202201.nc\n",
      "NO_TS_MO_Roompotsluis_202201.nc\n",
      "NO_TS_MO_RyeBayDWR_202201.nc\n",
      "NO_TS_MO_ScheurWielingenBuoy_202201.nc\n",
      "NO_TS_MO_SchiermonnikoogNoord_202201.nc\n",
      "NO_TS_MO_SchiermonnikoogWaggen_202201.nc\n",
      "NO_TS_MO_SchiermonnikoogWestgat_202201.nc\n",
      "NO_TS_MO_Schouwenbank2_202201.nc\n",
      "NO_TS_MO_Schouwenbank_202201.nc\n",
      "NO_TS_MO_StortemelkBoei_202201.nc\n",
      "NO_TS_MO_StortemelkOost_202201.nc\n",
      "NO_TS_MO_ThorntonbankSouthBuoy_202201.nc\n",
      "NO_TS_MO_TrapegeerBuoy_202201.nc\n",
      "NO_TS_MO_Uithuizerwad2_202201.nc\n",
      "NO_TS_MO_Uithuizerwad3_202201.nc\n",
      "NO_TS_MO_WaddenEierlandseGat_202201.nc\n",
      "NO_TS_MO_WandelaarBuoy_202201.nc\n",
      "NO_TS_MO_WesthinderBuoy_202201.nc\n",
      "NO_TS_MO_WielingenNoord_202201.nc\n",
      "NO_TS_MO_Wierumerwad2_202201.nc\n",
      "NO_TS_MO_Wierumerwad3_202201.nc\n",
      "NO_TS_MO_ZeebruggeZandopvangkadeBuoy_202201.nc\n",
      "NO_TS_MO_ZwinBuoy_202201.nc\n",
      "NO_TS_TG_DealPierTG_202201.nc\n",
      "NO_TS_TG_HastingsPierTG_202201.nc\n",
      "NO_TS_TG_HerneBayTG_202201.nc\n",
      "NO_TS_TG_LymingtonTG_202201.nc\n",
      "NO_TS_TG_SandownPierTG_202201.nc\n",
      "NO_TS_TG_SwanagePierTG_202201.nc\n"
     ]
    }
   ],
   "source": [
    "# Filter by location and parameters\n",
    "filtered_df = df[(df['geospatial_lat_min'] > south) &\n",
    "                 (df['geospatial_lat_max'] < north) &\n",
    "                 (df['geospatial_lon_min'] > west) &\n",
    "                 (df['geospatial_lon_max'] < east) &\n",
    "                 (df['geospatial_lon_max'] == df['geospatial_lon_min'] ) &\n",
    "                 (df['geospatial_lat_max'] == df['geospatial_lat_min'] ) &\n",
    "                 (df['parameters'].str.contains(\"VHM0\", na=False)) &\n",
    "                 #(df['parameters'].str.contains(\"VTZA\", na=False)) &\n",
    "                 #(df['parameters'].str.contains(\"VTM01\", na=False)) | (df['parameters'].str.contains(\"VTM02\", na=False))\n",
    "                 (df['file_name'].str.contains('202201'))\n",
    "                 #& (df['file_name'].str.contains('Q1'))\n",
    "                ]\n",
    "\n",
    "print(filtered_df.shape)\n",
    "\n",
    "# Copy df for later use\n",
    "file_df = filtered_df[['file_name']].copy()\n",
    "\n",
    "# Print basenames of filenames\n",
    "file_names = file_df['file_name']\n",
    "for name in file_names:\n",
    "    basename = os.path.basename(name)\n",
    "    print(basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b0a529",
   "metadata": {},
   "source": [
    "### Add to stations.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c14bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stations.txt\", \"w\") as f:\n",
    "    f.write('AkkaertSouthwestBuoy\\n')\n",
    "    f.write('Europlatform2\\n')\n",
    "    f.write('Europlatform3\\n')\n",
    "    f.write('F3platform\\n')\n",
    "    f.write('IJmuidenMunitiestort_\\n')\n",
    "    f.write('J61\\n')\n",
    "    f.write('K13a_\\n')\n",
    "    f.write('K141_\\n')\n",
    "    f.write('KeetenBoei\\n')\n",
    "    f.write('KwintebankBuoy\\n')\n",
    "    f.write('L91_\\n')\n",
    "    f.write('LichteilandGoeree1_\\n')\n",
    "    f.write('MaeslantkeringZeezijdeNoordMeetpaal\\n')\n",
    "    f.write('MaeslantkeringZeezijdeZuidMeetpaal\\n')\n",
    "    f.write('NieuwpoortBuoy\\n')\n",
    "    f.write('Nymindegab\\n')\n",
    "    f.write('Oosterschelde11\\n')\n",
    "    f.write('OstendEasternPalisadeBuoy\\n')\n",
    "    f.write('OverloopVanValkenisse\\n')\n",
    "    f.write('PasVanTerneuzenBoei\\n')\n",
    "    f.write('Q1_\\n')\n",
    "    f.write('WaddenEierlandseGat\\n')\n",
    "    f.write('WesthinderBuoy\\n')\n",
    "    f.write('ZeebruggeZandopvangkadeBuoy\\n')\n",
    "    f.write('ZwinBuoy\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b568f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stations_new.txt\", \"w\") as f:\n",
    "    f.write('6200145\\n')\n",
    "    f.write('6200293\\n')\n",
    "    f.write('6201045\\n')\n",
    "    f.write('6201050\\n')\n",
    "    f.write('6201058\\n')\n",
    "    f.write('A121_\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ba4c43",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf849155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_copernicus_data(filename, csv_path, output_directory, username, password, dataset_id):\n",
    "\n",
    "    with open (filename, \"r\") as f:\n",
    "        station_files = [line.strip() for line in f if line.strip()]\n",
    "        print(station_files)\n",
    "    \n",
    "    # Number of stations\n",
    "    n_stations = len(station_files)\n",
    "    print(f\"Number of stations: {n_stations}\")\n",
    "\n",
    "    # Modify station files\n",
    "    pattern = \"|\".join(re.escape(s) for s in station_files)  # escape in case of special characters\n",
    "\n",
    "    # Filter by location and parameters\n",
    "    filtered_df = df[(df['file_name'].str.contains(pattern, na=False)) & (df['file_name'].str.contains('202201')) ]\n",
    "    print(filtered_df.shape)\n",
    "\n",
    "    # Copy df for later use\n",
    "    file_df = filtered_df[['file_name']].copy()\n",
    "\n",
    "    # Print basenames of filenames\n",
    "    file_names = file_df['file_name']\n",
    "    for name in file_names:\n",
    "        basename = os.path.basename(name)\n",
    "        print(basename)\n",
    "    \n",
    "    # Update stations.csv file\n",
    "    stations_data = []\n",
    "\n",
    "    for station in station_files:\n",
    "        for name in filtered_df['file_name']:\n",
    "            if station in name:\n",
    "                row = filtered_df[filtered_df['file_name'] == name]\n",
    "                lat, lon = row['geospatial_lat_min'].values[0], row['geospatial_lon_min'].values[0]\n",
    "                stations_data.append({'station': station, 'lat': lat, 'lon': lon})\n",
    "\n",
    "    station_df = pd.DataFrame(stations_data)\n",
    "\n",
    "    # Keep only unique rows\n",
    "    df_unique = station_df.drop_duplicates(subset='station', keep='first')\n",
    "\n",
    "    # If file exists, load it and update\n",
    "    if os.path.exists(csv_path):\n",
    "        existing_df = pd.read_csv(csv_path)\n",
    "        # Concatenate and drop duplicates\n",
    "        updated_df = pd.concat([existing_df, df_unique], ignore_index=True)\n",
    "        updated_df = updated_df.drop_duplicates(subset='station', keep='first')\n",
    "    else:\n",
    "        updated_df = df_unique\n",
    "\n",
    "\n",
    "    # Save back\n",
    "    updated_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved stations to {csv_path}\")\n",
    "\n",
    "    # Filter by location and parameters\n",
    "    filtered_df = df[(df['file_name'].str.contains(pattern, na=False))\n",
    "                    & (df['file_name'].str.contains('2022')) \n",
    "                    ]\n",
    "\n",
    "    print(filtered_df.shape)\n",
    "\n",
    "    # Copy df for later use\n",
    "    file_df = filtered_df[['file_name']].copy()\n",
    "\n",
    "    # Create output txt file with files to download\n",
    "    with open(\"output.txt\", \"w\") as f:\n",
    "        for filename in file_df[\"file_name\"]:\n",
    "            f.write(str(filename) + \"\\n\")\n",
    "\n",
    "    # Define list with files to download\n",
    "    file_list = 'output.txt'\n",
    "\n",
    "    # Download data from Copernicus\n",
    "    print(\"Starting download...\")\n",
    "    copernicusmarine.get(\n",
    "        username=username,\n",
    "        password=password,\n",
    "        dataset_id=dataset_id,\n",
    "        index_parts=False,\n",
    "        file_list = file_list,\n",
    "        output_directory=output_directory,\n",
    "        no_directories=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d38615c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nc_to_csv(station_file, filename, obs_fldr, csv_fldr):\n",
    "    print(\"Converting .nc files to .csv files...\")\n",
    "\n",
    "    with open(station_file, \"r\") as f:\n",
    "        station_names = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    print(station_names)\n",
    "\n",
    "    # Get full file names from output.txt\n",
    "    with open(filename, \"r\") as f:\n",
    "        file_names = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    print(file_names)\n",
    "\n",
    "    for station in station_names:\n",
    "        stations_data = []\n",
    "\n",
    "        for name in file_names:\n",
    "            if station in name:\n",
    "                # Load the NetCDF file\n",
    "                basename = os.path.basename(name)\n",
    "                ds = xr.open_dataset(os.path.join(obs_fldr, basename))\n",
    "\n",
    "                # Convert to dataframe\n",
    "                df = ds.to_dataframe().reset_index()\n",
    "\n",
    "                # Extract the wanted variables\n",
    "                wanted = ['TIME', 'VHM0', 'VTZA', 'VMDR', 'VTPK']\n",
    "                cols = [col for col in wanted if col in df.columns]\n",
    "\n",
    "                df = df[cols].copy()\n",
    "                df = df.dropna()\n",
    "\n",
    "                stations_data.append(df)\n",
    "        \n",
    "        #print(f\"Processed {basename} for station {station}\")\n",
    "        \n",
    "        if stations_data:\n",
    "            station_df = pd.concat(stations_data, ignore_index=True)\n",
    "            output_csv = os.path.join(csv_fldr, f\"{station}.csv\")\n",
    "            station_df.to_csv(output_csv, index=False)\n",
    "            print(f\"Saved data for station {station} to {output_csv}\")\n",
    "        else:\n",
    "            print(f\"No data found for station {station}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9ec11b",
   "metadata": {},
   "source": [
    "### Download copernicus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e324103b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6200145', '6200293', '6201045', '6201050', '6201058', 'A121']\n",
      "Number of stations: 6\n",
      "(5, 12)\n",
      "NO_TS_MO_6200145_202201.nc\n",
      "NO_TS_MO_6201045_202201.nc\n",
      "NO_TS_MO_6201050_202201.nc\n",
      "NO_TS_MO_A121_202201.nc\n",
      "NO_TS_TG_A121TG_202201.nc\n",
      "Saved stations to ../observations/stations_new.csv\n",
      "(52, 12)\n",
      "Starting download...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2025-09-04T09:06:19Z - Selected dataset version: \"202311\"\n",
      "INFO - 2025-09-04T09:06:19Z - Selected dataset part: \"latest\"\n",
      "Downloading files: 100%|██████████| 52/52 [00:37<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "download_copernicus_data(filename=\"stations_new.txt\", csv_path='../observations/stations_new.csv', output_directory='./raw-data', username=username, password=password, dataset_id=dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835afbcb",
   "metadata": {},
   "source": [
    "### Convert nc data file to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb24747",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_nc_to_csv(station_file='stations_new.txt',filename=\"output.txt\", obs_fldr = 'raw-data', csv_fldr='../observations')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WaterBench-MIKE21SW-SouthernNorthSea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
